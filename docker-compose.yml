version: '2'

services:
  zoo1:
    image: wurstmeister/zookeeper
    restart: unless-stopped
    hostname: zoo1
    ports:
      - "2181:2181"
    container_name: pipeline-zookeeper


  kafka1:
    image: confluentinc/cp-kafka:4.0.0
    hostname: kafka1
    ports:
      - "9092:9092"
    environment:
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka1:9092"
      KAFKA_ZOOKEEPER_CONNECT: "zoo1:2181"
      KAFKA_BROKER_ID: 1
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    depends_on:
      - zoo1
    container_name: pipeline-kafka


  mock-producer:
    build: ./mock-producer
    depends_on:
      - kafka1
    container_name: pipeline-mock-producer


  mysql-consumer:
    build: ./mysql-consumer
    depends_on:
      - kafka1
      - mysql
    container_name: pipeline-mysql-consumer


  mysql:
    image: mysql:5.6.34
    restart: always
    environment:
      MYSQL_DATABASE: "sales_data_pipeline"
      MYSQL_ROOT_PASSWORD: "233"
      MYSQL_ALLOW_EMPTY_PASSWORD: "no"
    command: --init-file /tmp/create_db.sql
    volumes:
      - ./mysql/create_db.sql:/tmp/create_db.sql
    ports:
      - "3306:3306"
    container_name: pipeline-mysql


  postgres:
      image: postgres:9.6
      environment:
          - POSTGRES_USER=airflow
          - POSTGRES_PASSWORD=airflow
          - POSTGRES_DB=airflow

  webserver:
      image: puckel/docker-airflow:1.9.0-3
      restart: always
      depends_on:
          - postgres
      environment:
          - LOAD_EX=n
          - EXECUTOR=Local
      volumes:
          - ./airflow/dags:/usr/local/airflow/dags
          # Uncomment to include custom plugins
          # - ./plugins:/usr/local/airflow/plugins
      ports:
          - "8080:8080"
      command: webserver
      # healthcheck:
      #     test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
      #     interval: 30s
      #     timeout: 30s
      #     retries: 3
