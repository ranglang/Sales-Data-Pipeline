version: '2'

services:
  zoo1:
    image: wurstmeister/zookeeper
    restart: unless-stopped
    hostname: zoo1
    ports:
      - "2181:2181"
    container_name: pipeline-zookeeper


  kafka1:
    image: confluentinc/cp-kafka:4.0.0
    hostname: kafka1
    ports:
      - "9092:9092"
    environment:
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka1:9092"
      KAFKA_ZOOKEEPER_CONNECT: "zoo1:2181"
      KAFKA_BROKER_ID: 1
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    depends_on:
      - zoo1
    container_name: pipeline-kafka


  mock-producer:
    build: ./mock-producer
    depends_on:
      - kafka1
    container_name: pipeline-mock-producer


  mysql-consumer:
    build: ./mysql-consumer
    depends_on:
      - kafka1
      - mysql
    container_name: pipeline-mysql-consumer


  mysql:
    image: mysql:5.6.34
    restart: always
    environment:
      MYSQL_DATABASE: "sales_data_pipeline"
      MYSQL_ROOT_PASSWORD: "233"
      MYSQL_ALLOW_EMPTY_PASSWORD: "no"
    command: --init-file /tmp/create_db.sql
    volumes:
      - ./mysql/create_db.sql:/tmp/create_db.sql
    ports:
      - "3306:3306"
    container_name: pipeline-mysql


  spark-master:
    image: gettyimages/spark
    command: bin/spark-class org.apache.spark.deploy.master.Master -h master
    hostname: master
    environment:
      MASTER: spark://master:7077
      SPARK_CONF_DIR: /conf
      SPARK_PUBLIC_DNS: localhost
    expose:
      - 7001
      - 7002
      - 7003
      - 7004
      - 7005
      - 7006
      - 7077
      - 6066
    ports:
      - 4040:4040
      - 6066:6066
      - 7077:7077
      - 8080:8080
    volumes:
      - ./conf/master:/conf
      - ./data:/tmp/data
    container_name: pipeline-spark-master

  spark-worker:
    image: gettyimages/spark
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://master:7077
    hostname: worker
    environment:
      SPARK_CONF_DIR: /conf
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 1g
      SPARK_WORKER_PORT: 8881
      SPARK_WORKER_WEBUI_PORT: 8081
      SPARK_PUBLIC_DNS: localhost
    links:
      - spark-master
    expose:
      - 7012
      - 7013
      - 7014
      - 7015
      - 7016
      - 8881
    ports:
      - 8081:8081
    volumes:
      - ./conf/worker:/conf
      - ./data:/tmp/data
    container_name: pipeline-spark-worker


  postgres:
      image: postgres:9.6
      environment:
          - POSTGRES_USER=airflow
          - POSTGRES_PASSWORD=airflow
          - POSTGRES_DB=airflow
      container_name: pipeline-postgres


  airflow:
      build: puckel/docker-airflow:1.9.0-3
      restart: always
      depends_on:
          - postgres
      environment:
          - LOAD_EX=n
          - EXECUTOR=Local
      volumes:
          - ./airflow/bin/:/usr/local/airflow/bin
          - ./airflow/dags:/usr/local/airflow/dags
          - ./airflow/src:/usr/local/airflow/src
          # Uncomment to include custom plugins
          # - ./plugins:/usr/local/airflow/plugins
      ports:
          - "8080:8080"
      command: webserver
      container_name: pipeline-airflow
      # healthcheck:
      #     test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
      #     interval: 30s
      #     timeout: 30s
      #     retries: 3
